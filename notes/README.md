## Advanced Data Fetching & Rendering (Concept-1)

### Static Rendering (SSG)
- Page: About
- Generated at build time
- Used for static informational content

### Dynamic Rendering (SSR)
- Page: Dashboard
- Generated on every request
- Used for user-specific data

### Hybrid Rendering (ISR)
- Page: Notes
- Revalidated every 60 seconds
- Balances performance and freshness

### Reflection
If the app had 10x more users, we would reduce SSR usage and rely more on SSG and ISR to lower server load and improve scalability.



## CONCEPT-2:

## Environment-Aware Builds & Secrets Management (Concept-2)

This project uses separate environment configurations for development, staging, and production.

### Environment Files
- `.env.development` for local development
- `.env.staging` for staging builds
- `.env.production` for production builds
- `.env.example` is committed as a reference

All real secrets are excluded from version control using `.gitignore`.

### Secrets Management
Sensitive values such as API URLs and database credentials are stored securely using GitHub Secrets. These secrets are injected during build and runtime and are never hardcoded in the application.

### Environment-Specific Builds
Separate build commands are used to ensure each environment uses the correct configuration:
- `npm run build:staging`
- `npm run build:production`

### Reflection
Using multiple environments improves CI/CD reliability by preventing accidental production issues, enabling safer testing, and ensuring consistent deployments across different stages.



**Benefits:**
- Faster deployments
- Reduced manual errors
- Reliable production releases

---

### Secrets & Environment Management

Sensitive data is never committed to the repository.

- Secrets are stored using:
  - GitHub Secrets
  - Cloud provider environment variables
- Separate environments:
  - Development
  - Staging
  - Production

Examples:
- Database URLs
- API keys
- Authentication secrets

---

### Cloud Deployment (Conceptual)

The application is designed to be deployed on cloud services such as:

- **AWS EC2 / Elastic Beanstalk**
- **Azure App Service**

Supporting services:
- PostgreSQL (RDS / Azure Database)
- Redis (ElastiCache)
- Object Storage (S3 / Blob Storage)

---

### Deployment Challenges & Learnings

**Challenges:**
- Handling environment-specific variables
- Debugging CI/CD failures due to missing secrets

**What Worked Well:**
- Docker ensured consistent builds
- CI/CD automation reduced manual effort

**Future Improvements:**
- Add staging environment
- Improve monitoring and logging
- Explore Infrastructure as Code (Terraform/Bicep)

---

## Docker & Compose Setup for Local Development

This project uses Docker and Docker Compose to containerize the full-stack application, including the Next.js app, PostgreSQL database, and Redis cache. This setup eliminates the "it works on my machine" problem and ensures consistency across all team members' development environments.

### ğŸ“¦ Architecture Overview

The application consists of three main services:
1. **Next.js App** - Frontend and backend application (Port 3000)
2. **PostgreSQL Database** - Relational database for persistent data (Port 5432)
3. **Redis Cache** - In-memory cache for session management and performance (Port 6379)

All services run in isolated Docker containers connected via a shared bridge network (`campusnotes-network`).

### ğŸ—ï¸ Dockerfile Explanation

The Dockerfile uses a **multi-stage build** approach for optimization:

#### Stage 1: Dependencies
```dockerfile
FROM node:20-alpine AS deps
```
- Uses lightweight Alpine Linux base image
- Installs only production dependencies (`npm ci --only=production`)
- Reduces final image size

#### Stage 2: Builder
```dockerfile
FROM node:20-alpine AS builder
```
- Installs all dependencies (including dev dependencies)
- Copies source code and builds the Next.js application
- Generates optimized production build with `npm run build`

#### Stage 3: Runner (Production)
```dockerfile
FROM node:20-alpine AS runner
```
- Creates a minimal production image
- Uses non-root user (`nextjs`) for security
- Copies only necessary built files from builder stage
- Includes health check for container monitoring
- Final image size is significantly smaller than single-stage builds

**Key Features:**
- Multi-stage builds reduce image size by ~70%
- Non-root user enhances security
- Health checks enable automatic container monitoring
- Standalone output mode optimized for Docker deployment

### ğŸ³ Docker Compose Configuration

The `docker-compose.yml` orchestrates all three services:

#### Database Service (db)
```yaml
db:
  image: postgres:16-alpine
  environment:
    POSTGRES_USER: postgres
    POSTGRES_PASSWORD: postgres
    POSTGRES_DB: campusnotes
```
- Uses official PostgreSQL 16 Alpine image
- Persistent storage via named volume `postgres_data`
- Health checks ensure database is ready before app starts
- Port 5432 exposed for local database access

#### Redis Service
```yaml
redis:
  image: redis:7-alpine
  command: redis-server --appendonly yes --requirepass redis
```
- Uses official Redis 7 Alpine image
- Enables data persistence with AOF (Append-Only File)
- Password protection for security
- Port 6379 exposed for local cache access

#### Application Service (app)
```yaml
app:
  build:
    context: .
    dockerfile: Dockerfile
  depends_on:
    db:
      condition: service_healthy
    redis:
      condition: service_healthy
```
- Builds from local Dockerfile
- Waits for database and Redis to be healthy before starting
- Connects to services using Docker DNS (hostnames: `db`, `redis`)
- Environment variables injected for database and cache connections

### ğŸŒ Network Configuration

All services are connected via a custom bridge network:
```yaml
networks:
  campusnotes-network:
    driver: bridge
```

**Benefits:**
- Services can communicate using service names (e.g., `db`, `redis`)
- Isolated from other Docker networks
- Automatic DNS resolution between containers
- Secure internal communication

### ğŸ’¾ Volume Configuration

Three named volumes ensure data persistence:
```yaml
volumes:
  postgres_data:    # Database data
  redis_data:       # Redis cache persistence
  app_logs:         # Application logs
```

**Purpose:**
- Data survives container restarts
- Can be backed up independently
- Shared across container recreations

### ğŸ” Environment Variables

Environment variables are defined in `.env` file (not committed):
```env
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=campusnotes
REDIS_PASSWORD=redis
DATABASE_URL=postgresql://postgres:postgres@db:5432/campusnotes
```

**Security Best Practices:**
- Never commit `.env` file to version control
- Use `.env.example` as template
- Different credentials for each environment
- Secrets injected at runtime

### ğŸš€ Running the Application

#### Prerequisites
- Docker Desktop installed and running
- Docker Compose v2.0 or higher

#### Start All Services
```bash
docker-compose up --build
```

This command:
1. Builds the Next.js app Docker image
2. Pulls PostgreSQL and Redis images
3. Creates network and volumes
4. Starts all containers in correct order
5. Shows logs from all services

#### Run in Detached Mode
```bash
docker-compose up -d --build
```

#### View Logs
```bash
docker-compose logs -f app    # App logs only
docker-compose logs -f db     # Database logs
docker-compose logs -f redis  # Redis logs
docker-compose logs -f        # All logs
```

#### Stop Services
```bash
docker-compose down           # Stop and remove containers
docker-compose down -v        # Also remove volumes (data loss!)
```

#### Verify Running Containers
```bash
docker ps
```

Expected output:
```
CONTAINER ID   IMAGE              STATUS          PORTS                    NAMES
xxxxxxxxxxxx   campusnotes-app    Up 2 minutes    0.0.0.0:3000->3000/tcp  campusnotes-app
xxxxxxxxxxxx   postgres:16-alpine Up 2 minutes    0.0.0.0:5432->5432/tcp  campusnotes-db
xxxxxxxxxxxx   redis:7-alpine     Up 2 minutes    0.0.0.0:6379->6379/tcp  campusnotes-redis
```

### âœ… Verification Steps

1. **App Accessibility**
   - Open browser: http://localhost:3000
   - Should see Next.js app homepage

2. **Database Connection**
   ```bash
   docker exec -it campusnotes-db psql -U postgres -d campusnotes
   ```

3. **Redis Connection**
   ```bash
   docker exec -it campusnotes-redis redis-cli -a redis
   > PING
   PONG
   ```

4. **Health Checks**
   ```bash
   docker inspect campusnotes-app | grep -A 10 Health
   ```

### ğŸ› Common Issues & Solutions

#### Issue 1: Port Already in Use
**Error:** `Error starting userland proxy: listen tcp 0.0.0.0:3000: bind: address already in use`

**Solution:**
```bash
# Find process using port
netstat -ano | findstr :3000
# Kill the process or change port in docker-compose.yml
```

#### Issue 2: Permission Errors on Windows
**Error:** `permission denied while trying to connect to Docker daemon`

**Solution:**
- Ensure Docker Desktop is running as Administrator
- Add user to `docker-users` group
- Restart Docker Desktop

#### Issue 3: Build Fails on Dependencies
**Error:** `npm ERR! Cannot find module`

**Solution:**
```bash
# Clear Docker build cache
docker-compose build --no-cache
```

#### Issue 4: Database Connection Refused
**Error:** `Error: connect ECONNREFUSED`

**Solution:**
- Check if `depends_on` with health checks is properly configured
- Verify DATABASE_URL uses service name `db` not `localhost`
- Wait for health checks to pass:
```bash
docker-compose logs db | grep "ready to accept connections"
```

#### Issue 5: Slow Build Times
**Solution:**
- Use `.dockerignore` to exclude unnecessary files
- Enable Docker BuildKit:
```bash
$env:DOCKER_BUILDKIT=1   # PowerShell
docker-compose build
```

### ğŸ“¸ Screenshots

**Terminal Output: Building Services**
```
[+] Building 45.2s (18/18) FINISHED
 => [app internal] load build definition from Dockerfile
 => [app internal] load .dockerignore
 => [app stage-2 1/6] FROM docker.io/library/node:20-alpine
 => [app] CACHED [deps 2/3] COPY package*.json ./
 => [app builder 4/6] COPY . .
 => [app builder 5/6] RUN npm run build
 => [app] exporting to image
 => => exporting layers
 => => writing image sha256:xxxx
```

**Terminal Output: Services Running**
```
campusnotes-db     | database system is ready to accept connections
campusnotes-redis  | Ready to accept connections
campusnotes-app    | â–² Next.js 16.0.10
campusnotes-app    | - Local:        http://localhost:3000
campusnotes-app    | âœ“ Ready in 2.3s
```

**Docker Desktop Dashboard**
- Shows all three containers running (green status)
- Memory and CPU usage visible
- Logs accessible for each service

### ğŸ¯ Benefits of This Setup

1. **Team Consistency**
   - Every developer runs identical environment
   - No "works on my machine" issues
   - Same Node version, database version, etc.

2. **Quick Onboarding**
   - New team member runs: `docker-compose up`
   - Entire stack ready in minutes
   - No manual installation of dependencies

3. **Production Parity**
   - Development environment mirrors production
   - Catch environment-specific bugs early
   - Confident deployments

4. **Easy Cleanup**
   - Remove everything: `docker-compose down -v`
   - Fresh start anytime
   - No leftover processes or data

5. **Scalability**
   - Easy to add new services (e.g., Elasticsearch, RabbitMQ)
   - Service discovery handled by Docker
   - Load balancing with Docker Swarm/Kubernetes

### ğŸ”„ CI/CD Integration

This Docker setup integrates seamlessly with CI/CD pipelines:
```yaml
# GitHub Actions example
- name: Build Docker image
  run: docker-compose build app
  
- name: Run tests in container
  run: docker-compose run app npm test
```

### ğŸ“ Reflections

**What Went Well:**
- Multi-stage builds significantly reduced image size (from 1.2GB to 350MB)
- Health checks prevented race conditions between services
- Named volumes ensured data persistence across container restarts
- Custom network provided clean service-to-service communication

**Challenges Faced:**
1. **Initial Build Time**: First build took ~5 minutes due to npm install
   - *Solution*: Implemented layer caching and `.dockerignore`
   
2. **Windows File Path Issues**: Volume mounts had backslash problems
   - *Solution*: Used forward slashes and proper path escaping
   
3. **Database Connection Timing**: App started before database was ready
   - *Solution*: Added health checks and `depends_on` conditions

4. **Port Conflicts**: Local PostgreSQL conflicted with Docker port 5432
   - *Solution*: Stopped local services or remapped Docker ports

**Lessons Learned:**
- Always use health checks for service dependencies
- Multi-stage builds are essential for production images
- .dockerignore is as important as .gitignore
- Docker networks eliminate hardcoded IPs
- Named volumes are crucial for data persistence

**Future Improvements:**
- Add Nginx reverse proxy for production
- Implement Docker secrets for sensitive data
- Add monitoring with Prometheus/Grafana containers
- Set up automated backups for database volume
- Use Docker Swarm or Kubernetes for orchestration

### ğŸ¥ Video Demo Checklist

For your submission video, demonstrate:
1. âœ… Show `Dockerfile` with multi-stage build explanation
2. âœ… Show `docker-compose.yml` with all three services
3. âœ… Run `docker-compose up --build` command
4. âœ… Show `docker ps` output with all containers running
5. âœ… Open browser at http://localhost:3000
6. âœ… Verify database connection
7. âœ… Verify Redis connection
8. âœ… Explain how this helps team onboarding

**Creative Reflection Answer:**
"If our team had to onboard a new developer tomorrow, Docker Compose makes it incredibly fast and smooth because instead of spending hours installing Node.js, PostgreSQL, Redis, configuring environment variables, and troubleshooting version mismatches, they simply run one command: `docker-compose up`. Within 5 minutes, they have a fully functional development environment that's identical to everyone else's. No setup documentation needed, no dependency conflicts, no platform-specific issues. They can start contributing to the codebase immediately, and we save days of setup time and frustration."

### ğŸ“š Additional Resources

- [Docker Official Documentation](https://docs.docker.com/)
- [Docker Compose Documentation](https://docs.docker.com/compose/)
- [Next.js Docker Deployment](https://nextjs.org/docs/deployment#docker-image)
- [PostgreSQL Docker Hub](https://hub.docker.com/_/postgres)
- [Redis Docker Hub](https://hub.docker.com/_/redis)
- [Multi-stage Build Best Practices](https://docs.docker.com/build/building/multi-stage/)

---

## Prisma ORM Setup & Client Initialisation (Concept-7)

### Purpose of Prisma ORM

Prisma is a modern, type-safe Object-Relational Mapping (ORM) tool that provides:
- **Type Safety**: Automatically generated TypeScript types from your database schema
- **Query Reliability**: Compile-time validation for database queries
- **Developer Productivity**: Auto-generated queries reduce boilerplate and manual SQL
- **Database Agnostic**: Switch between PostgreSQL, MySQL, SQLite, and other databases with minimal changes
- **Declarative Schema**: Define your database structure in a single, easy-to-read schema file

### Setup Steps Completed

#### 1. **Installation & Initialization**
```bash
npm install prisma --save-dev
npx prisma init
```
This created:
- `/prisma/schema.prisma` - Database schema definition file
- `.env` - Environment variables for database connection

#### 2. **Database Configuration**
Updated `.env` with PostgreSQL connection string:
```
DATABASE_URL="postgresql://user:password@localhost:5432/campusnotes"
```

#### 3. **Schema Definition**
Defined comprehensive models for Campus Notes application in `prisma/schema.prisma`:

**Core Models:**
- **User**: User accounts with authentication
- **Course**: Academic courses/subjects
- **Note**: Individual notes with content
- **Folder**: Organizational folders for notes
- **Tag**: Tagging system for note categorization
- **CourseEnrollment**: User-Course relationships
- **TagOnNote**: Note-Tag many-to-many relationships

**Key Features:**
- Unique constraints on email, course codes, and user-tag combinations
- Foreign key relationships with cascade delete
- Timestamps for created/updated tracking
- Type safety through Prisma's type generation

#### 4. **Prisma Client Initialization**
Created `src/lib/prisma.ts` to initialize the Prisma Client:
```typescript
import { PrismaClient } from '@prisma/client';

const globalForPrisma = global as unknown as { prisma: PrismaClient };

export const prisma =
  globalForPrisma.prisma ||
  new PrismaClient({
    log: ['query', 'info', 'warn', 'error'],
  });

if (process.env.NODE_ENV !== 'production') globalForPrisma.prisma = prisma;
```

**Why Single Instance?**
- Prevents connection pool exhaustion during development
- Reuses the same database connection across hot module reloads
- Production automatically creates fresh instances as needed

#### 5. **Prisma Client Generation**
```bash
npx prisma generate
```
Generated TypeScript types at: `node_modules/@prisma/client`

Output:
```
âœ” Generated Prisma Client (v6.19.2) to .\node_modules\@prisma\client in 179ms
```

### Testing the Connection

Created `src/lib/db-test.ts` with example queries:

```typescript
import { prisma } from '@/lib/prisma';

export async function testDatabaseConnection() {
  const users = await prisma.user.findMany();
  console.log('âœ… Database connection successful!');
  return users;
}

export async function getUserWithNotesAndCourses(userId: number) {
  const user = await prisma.user.findUnique({
    where: { id: userId },
    include: {
      notes: { include: { course: true, tags: true } },
      courses: { include: { course: true } },
    },
  });
  return user;
}
```

### Key Advantages of Prisma vs Raw SQL

#### âœ… **Prisma Advantages:**
1. **Type Safety**: Full IDE autocomplete and compile-time error checking
2. **Less Code**: One-liner queries instead of verbose SQL
3. **Automatic Migrations**: Prisma handles schema changes safely
4. **Query Validation**: Invalid queries caught at development time
5. **Developer Experience**: Clear, readable API
6. **Performance Optimization**: Built-in query optimization and lazy loading

#### ğŸ“ **When Raw SQL is Preferred:**
1. **Complex Aggregations**: Multiple JOINs, GROUP BY, window functions
2. **Performance Critical**: When hand-optimized SQL outperforms ORM
3. **Legacy Systems**: Existing complex queries not easily translatable
4. **Database-Specific Features**: Advanced vendor-specific features
5. **Real-time Analytics**: Large data processing operations

### Database Schema Visualization

**User-Course Enrollment (Many-to-Many):**
```
User --> CourseEnrollment <-- Course
```

**Note Organization:**
```
User --> Note <-- Course
         |
         +-- Folder
         |
         +-- TagOnNote --> Tag
```

**Relationships & Constraints:**
- Users can have multiple notes and courses
- Notes belong to exactly one user and course
- Tags are user-specific for privacy
- Cascade delete ensures data integrity

### Project Structure
```
src/
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ prisma.ts          # Prisma Client singleton
â”‚   â””â”€â”€ db-test.ts         # Example queries and tests
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ layout.js
â”‚   â”œâ”€â”€ page.js
â”‚   â””â”€â”€ ...pages
â””â”€â”€ ...

prisma/
â”œâ”€â”€ schema.prisma          # Database schema definition
â””â”€â”€ migrations/            # Auto-generated migration files
```

### How Prisma Improves Development

1. **Rapid Development**: Focus on business logic, not database plumbing
2. **Maintainability**: Self-documenting schema, clear relationships
3. **Testing**: Easier to mock and test database interactions
4. **Collaboration**: Team members understand data structure immediately
5. **Scalability**: Simple to add new models and relationships

### Creative Reflection: Prisma vs Raw SQL

**Q: If Prisma automatically generates database queries for you, what advantages does this bring compared to writing raw SQL â€” and when might you still prefer raw SQL?**

**A:** Prisma provides several game-changing advantages over raw SQL:

1. **Type Safety & Developer Experience**: Prisma generates TypeScript types automatically from your schema, so you get IDE autocomplete for all queries. With raw SQL, you're writing strings and manually managing type definitions. Prisma catches errors at compile-time instead of runtime.

2. **Productivity**: A Prisma query like `prisma.user.findMany({ include: { notes: true } })` accomplishes in one line what takes 10+ lines of raw SQL with manual result mapping. This accelerates development significantly.

3. **Maintainability**: When schema changes occur, Prisma migrations handle the heavy lifting. With raw SQL, you're managing migrations manually and risk inconsistencies.

4. **Database Agnosticity**: Switch from PostgreSQL to MySQL with zero query changes. Raw SQL is database-specific.

However, raw SQL still wins in specific scenarios:
- **Complex Aggregations**: Multi-table aggregations with window functions or complex GROUP BY operations
- **Performance-Critical Operations**: Sometimes hand-crafted SQL optimizations outperform ORM query generation
- **Legacy Systems**: Existing complex procedures and triggers are easier to work with directly
- **Real-time Analytics**: Large batch operations or report generation often benefit from optimized SQL

**Conclusion**: Use Prisma as your default for 95% of operations to maximize developer productivity and code quality. Reserve raw SQL for the remaining 5% where performance or complexity demands it. Prisma even supports raw SQL queries when needed, giving you the best of both worlds.

### Next Steps

1. **Create Migrations**: `npx prisma migrate dev --name init`
2. **Seed Database**: Create sample data for testing
3. **Build API Routes**: Use Prisma in Next.js API routes
4. **Implement CRUD**: Create endpoints for notes, courses, etc.
5. **Add Authentication**: Secure endpoints with user context

---

## Database Migrations & Seed Scripts (Concept-7b)

### Understanding Database Migrations

A migration is a versioned record of changes to your database schema. It captures what changed (added tables, modified fields, etc.) and ensures consistency across development, staging, and production environments.

**Why Migrations Matter:**
- âœ… Version control for database schema (like Git for code)
- âœ… Reproducibility across team members and environments
- âœ… Safe rollback capability if issues arise
- âœ… Audit trail of all schema changes
- âœ… Prevents manual SQL errors and inconsistencies

### Migration Workflow

#### 1. **Create and Run Your First Migration**

After updating `prisma/schema.prisma` with your models, create the initial migration:

```bash
npx prisma migrate dev --name init_schema
```

**What Prisma does:**
1. Generates SQL migration files in `prisma/migrations/[timestamp]_init_schema/`
2. Applies the migration to your PostgreSQL database
3. Updates the `_prisma_migrations` table to track migration history
4. Regenerates the Prisma Client with updated types

**Example Output:**
```
âœ” Successfully created 7 new tables
âœ” Migration: 20260122_init_schema (XXms)
âœ” Generated Prisma Client (v6.19.2)
```

#### 2. **Understanding Generated Migration Files**

Each migration creates an SQL file. For Campus Notes, `init_schema.sql` contains:

```sql
-- CreateTable User
CREATE TABLE "User" (
  "id" SERIAL NOT NULL PRIMARY KEY,
  "email" TEXT NOT NULL UNIQUE,
  "name" TEXT NOT NULL,
  "password" TEXT NOT NULL,
  "avatar" TEXT,
  "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
  "updatedAt" TIMESTAMP(3) NOT NULL,
  CONSTRAINT "User_pkey" PRIMARY KEY ("id")
);

-- CreateTable Course
CREATE TABLE "Course" (
  "id" SERIAL NOT NULL PRIMARY KEY,
  "title" TEXT NOT NULL,
  "code" TEXT NOT NULL UNIQUE,
  "description" TEXT,
  "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
  "updatedAt" TIMESTAMP(3) NOT NULL
);

-- [Additional tables for Note, Folder, Tag, CourseEnrollment, TagOnNote...]
```

**Key Observations:**
- All tables created atomically in one transaction
- Foreign keys with cascade delete policies
- Unique constraints for data integrity
- Timestamps for audit trails

#### 3. **Add or Modify Models and Create New Migrations**

When you need to add a new feature (e.g., a Notification model):

```prisma
model Notification {
  id        Int       @id @default(autoincrement())
  userId    Int
  title     String
  message   String
  isRead    Boolean   @default(false)
  createdAt DateTime  @default(now())
  
  user      User      @relation(fields: [userId], references: [id], onDelete: Cascade)
}
```

Create a new migration:

```bash
npx prisma migrate dev --name add_notification_table
```

This creates a separate migration file capturing only the new changes.

#### 4. **Reset and Reapply Migrations (Development Only)**

To clear your local database and start fresh:

```bash
npx prisma migrate reset
```

**Warning:** This is destructive! Only use in development. Prisma will:
1. Drop the entire database
2. Create a new empty database
3. Re-apply all migrations in order
4. Optionally run seed script

### Database Seeding

Seeding populates your database with initial data needed for development and testing.

#### **Our Seed Script: `prisma/seed.ts`**

The seed script uses `upsert` for idempotency â€” running it multiple times won't create duplicates:

```typescript
// Users (with upsert for idempotency)
const alice = await prisma.user.upsert({
  where: { email: 'alice@campusnotes.com' },
  update: {},
  create: {
    email: 'alice@campusnotes.com',
    name: 'Alice Johnson',
    password: 'hashed_password_123',
  },
});

// Courses (3 sample courses)
const csAlgorithms = await prisma.course.upsert({
  where: { code: 'CS101' },
  update: {},
  create: {
    code: 'CS101',
    title: 'Introduction to Algorithms',
    description: 'Comprehensive study of algorithm design',
  },
});

// Course Enrollments (user-course relationships)
await prisma.courseEnrollment.upsert({
  where: { userId_courseId: { userId: alice.id, courseId: csAlgorithms.id } },
  update: {},
  create: {
    userId: alice.id,
    courseId: csAlgorithms.id,
  },
});

// Folders, Tags, Notes, and Tag associations follow the same pattern
```

**Why Upsert?**
- Idempotent: Safe to run multiple times
- Creates if doesn't exist, updates if it does
- Prevents duplicate key errors
- Perfect for seeding!

#### **Running the Seed Script**

```bash
# Option 1: Explicit seed command
npm run db:seed

# Option 2: Via Prisma CLI
npx prisma db seed

# Option 3: Auto-seed on migration reset
npx prisma migrate reset  # This auto-runs seed at the end
```

**Sample Output:**
```
ğŸŒ± Starting database seeding...

ğŸ‘¤ Creating users...
âœ… Created/Updated 3 users

ğŸ“š Creating courses...
âœ… Created/Updated 3 courses

ğŸ“ Creating course enrollments...
âœ… Created/Updated 4 course enrollments

ğŸ“ Creating folders...
âœ… Created/Updated 3 folders

ğŸ·ï¸  Creating tags...
âœ… Created/Updated 3 tags

ğŸ“– Creating notes...
âœ… Created/Updated 4 notes

ğŸ”— Creating note-tag associations...
âœ… Created/Updated 4 note-tag associations

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ¨ Database seeding completed successfully! âœ¨
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š Seeded Data Summary:
   â€¢ Users: 3
   â€¢ Courses: 3
   â€¢ Course Enrollments: 4
   â€¢ Folders: 3
   â€¢ Notes: 4
   â€¢ Tags: 3
   â€¢ Note-Tag Associations: 4

ğŸ’¡ Pro Tip: Run "npm run db:studio" to view the data in Prisma Studio!
```

#### **Verifying Seeded Data with Prisma Studio**

Prisma Studio is a GUI for viewing and editing your database:

```bash
npm run db:studio
# Opens: http://localhost:5555
```

Features:
- Browse all tables and records
- Filter and search data
- Edit records directly
- Run queries
- Perfect for verification!

### Idempotency & Safe Seeding

**Idempotency Principle:** Running the seed script multiple times produces the same result.

Our implementation ensures this:

```typescript
await prisma.tag.upsert({
  where: { userId_name: { userId: alice.id, name: 'Important' } },
  update: {},  // Don't change if exists
  create: {    // Create only if doesn't exist
    name: 'Important',
    userId: alice.id,
  },
});
```

**Test Idempotency:**
```bash
npm run db:seed
# Run again - should see "Updated" messages, not "Created"
npm run db:seed
# No errors, data unchanged âœ“
```

### Migration Rollback & Recovery

#### **Rolling Back the Last Migration**

```bash
# Rollback to previous migration (breaks forward-only migrations)
npx prisma migrate resolve --rolled-back <migration_name>
```

**Important:** Prisma expects migrations to be applied sequentially. Better approach:

#### **Recommended: Create a New Migration**

If a migration went wrong:

```typescript
// In new migration, undo the problematic change
// For example, if you added a field you didn't want:

// Add a new migration to remove it
ALTER TABLE "Note" DROP COLUMN "unwantedField";
```

#### **For Development: Reset Everything**

```bash
# Clean slate - drops, rebuilds, reseeds
npx prisma migrate reset
```

### Production Data Protection

**Critical Steps Before Running Migrations in Production:**

1. **Full Database Backup**
   ```bash
   # PostgreSQL backup
   pg_dump -U postgres campusnotes > backup_$(date +%Y%m%d_%H%M%S).sql
   ```

2. **Test in Staging First**
   - Run migration in staging environment
   - Verify data integrity
   - Confirm performance impact
   - Test rollback procedure

3. **Planned Downtime Window**
   - Announce maintenance window
   - Disable critical features during migration
   - Have rollback plan ready

4. **Blue-Green Deployment**
   - Keep old database running (blue)
   - Create new database with migration (green)
   - Switch traffic after verification
   - Keep blue as fallback

5. **Zero-Downtime Strategies**
   - Use feature flags to toggle new schema
   - Dual-write pattern (write to both old and new)
   - Gradual rollout with canary testing

6. **Monitoring & Alerts**
   - Monitor database performance
   - Set up alerts for errors
   - Have DBA on standby
   - Document all steps

7. **Verification Checklist**
   - âœ… All tables created successfully
   - âœ… Foreign keys established
   - âœ… Indexes created
   - âœ… Data integrity checks passed
   - âœ… Performance metrics acceptable
   - âœ… Application works with new schema

### Database Setup Commands Reference

**Quick Setup:**
```bash
# Start PostgreSQL via Docker
docker-compose up -d db

# Wait for database to be ready
sleep 5

# Run initial migration and seed
npm run db:migrate -- --name init_schema
npm run db:seed

# Verify in Prisma Studio
npm run db:studio
```

**Useful Commands:**
```bash
# Generate Prisma Client types
npm run db:generate

# Create new migration
npm run db:migrate -- --name add_feature_name

# Reset database (development only)
npm run db:reset

# Open Prisma Studio
npm run db:studio

# Check migration status
npx prisma migrate status
```

### Migration Best Practices

1. **One Migration Per Change** - Keep migrations small and focused
2. **Always Test Locally First** - Catch errors before production
3. **Write Idempotent Seeds** - Use `upsert` to prevent duplicates
4. **Document Migration Purpose** - Use clear names like `add_notification_table`
5. **Version Control Migrations** - Commit `.prisma/migrations/` folder
6. **Never Edit Applied Migrations** - Create new migration instead
7. **Test Rollback Procedure** - Ensure you can recover if needed
8. **Monitor Post-Migration** - Watch for errors and performance issues

### Production Data Protection Reflection

**Q: If your app were live in production, what steps would you take before running a migration to make sure no data is lost or corrupted?**

**A:** Running migrations in production requires extreme caution. Here's my approach:

1. **Comprehensive Backup Strategy**
   - Full database backup to encrypted off-site storage
   - Transaction logs for point-in-time recovery
   - Test restore procedure regularly

2. **Staging Environment Validation**
   - Mirror production data (anonymized) to staging
   - Run migration in staging first
   - Verify all data integrity with detailed queries
   - Load test to ensure performance

3. **Careful Planning**
   - Schedule during low-traffic window (2-4 AM)
   - Communicate maintenance window to users
   - Have rollback plan documented and tested
   - Ensure DBA and engineering team available

4. **Execution Protocol**
   - Enable read-only mode before migration
   - Create pre-migration backup
   - Run migration in transaction (if possible)
   - Verify data integrity post-migration
   - Monitor for 24 hours after

5. **Monitoring & Rollback**
   - Set up performance alerts
   - Monitor error logs in real-time
   - Have quick rollback procedure ready
   - Be prepared to restore from backup

6. **Zero-Downtime Techniques**
   - Use blue-green deployment
   - Feature flags to control schema usage
   - Gradual rollout with canary testing
   - Keep backward compatibility

**Key Principle:** Production migrations should be boring, well-tested, and have multiple safety nets. Better to spend 2 hours planning than 2 days recovering from data loss!

---

## Database Migrations & Seed Scripts (Concept-8)

### Understanding Database Migrations

Database migrations are version-controlled changes to your database schema. They ensure:
- **Consistency**: Same database structure across all environments (local, staging, production)
- **Reversibility**: Ability to rollback to previous states if needed
- **Traceability**: Complete history of schema changes over time
- **Team Collaboration**: Everyone applies the same changes in the same order

### Migration Workflow

#### 1. **Create Your First Migration**

After defining your schema in `prisma/schema.prisma`, generate a migration:

```bash
npx prisma migrate dev --name init_schema
```

This command:
- Creates a new migration file in `prisma/migrations/[timestamp]_init_schema/`
- Generates the SQL to transform your database
- Applies the migration to your local database
- Generates the Prisma Client with updated types

**Output Example:**
```
âœ” Created migration: prisma/migrations/20260122074531_init_schema

The following migration(s) have been created and applied:

migrations/
  â””â”€ 20260122074531_init_schema/
    â””â”€ migration.sql

âœ” Generated Prisma Client (v6.19.2)
```

#### 2. **Making Schema Changes**

When you need to add or modify models:

1. Update `prisma/schema.prisma`
2. Run migration command:
   ```bash
   npx prisma migrate dev --name add_new_feature
   ```
3. Prisma generates SQL, applies it, and regenerates types

**Example: Adding a new field to User model:**

```prisma
model User {
  id        Int       @id @default(autoincrement())
  email     String    @unique
  name      String
  password  String
  avatar    String?
  role      String    @default("student")  // New field
  createdAt DateTime  @default(now())
  updatedAt DateTime  @updatedAt
  
  // Relations...
}
```

Then:
```bash
npx prisma migrate dev --name add_role_to_user
```

#### 3. **Viewing Migrations**

All migrations are stored in `prisma/migrations/` with timestamps:

```
prisma/
â”œâ”€â”€ migrations/
â”‚   â”œâ”€â”€ migration_lock.toml         # Locks migration engine
â”‚   â”œâ”€â”€ 20260122074531_init_schema/
â”‚   â”‚   â””â”€â”€ migration.sql           # Initial schema SQL
â”‚   â””â”€â”€ 20260122074532_add_role_to_user/
â”‚       â””â”€â”€ migration.sql           # Add role field SQL
â””â”€â”€ schema.prisma
```

### Database Seeding

#### What is Seeding?

Seeding is the process of inserting initial (or test) data into your database. Benefits:
- **Consistent test data**: Everyone has the same starting dataset
- **Development efficiency**: No need to manually enter data
- **Production safety**: Predictable production setup
- **Idempotency**: Re-running seed doesn't create duplicates

#### Our Seed Script

Located in `prisma/seed.ts`, it creates sample data including:

```typescript
// 3 Sample Users
- Alice Johnson (alice@campusnotes.com)
- Bob Smith (bob@campusnotes.com)
- Charlie Brown (charlie@campusnotes.com)

// 3 Sample Courses
- CS101: Introduction to Algorithms
- CS201: Database Systems
- WEB101: Full Stack Web Development

// 4 Sample Notes with course associations
- Big O Notation Explained
- ACID Properties in Databases
- React Hooks Tutorial
- SQL JOIN Operations

// 3 Custom Tags
- Important
- Review Later
- Urgent

// 4 Note-Tag Associations
```

#### Running the Seed Script

```bash
# Option 1: Using npm script
npm run db:seed

# Option 2: Using Prisma directly
npx prisma db seed

# Option 3: Combined with migration
npx prisma migrate dev --name init_schema
# (Automatically runs seed if configured)
```

**Seed Output Example:**
```
ğŸŒ± Starting database seeding...

ğŸ‘¤ Creating users...
âœ… Created/Updated 3 users

ğŸ“š Creating courses...
âœ… Created/Updated 3 courses

ğŸ“ Creating course enrollments...
âœ… Created/Updated 4 course enrollments

ğŸ“ Creating folders...
âœ… Created/Updated 3 folders

ğŸ·ï¸  Creating tags...
âœ… Created/Updated 3 tags

ğŸ“– Creating notes...
âœ… Created/Updated 4 notes

ğŸ”— Creating note-tag associations...
âœ… Created/Updated 4 note-tag associations

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ¨ Database seeding completed successfully! âœ¨
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š Seeded Data Summary:
   â€¢ Users: 3
   â€¢ Courses: 3
   â€¢ Course Enrollments: 4
   â€¢ Folders: 3
   â€¢ Notes: 4
   â€¢ Tags: 3
   â€¢ Note-Tag Associations: 4

ğŸ’¡ Pro Tip: Run "npm run db:studio" to view the data in Prisma Studio!
```

### Using Prisma Studio

Prisma Studio provides a GUI for viewing and editing your database:

```bash
npm run db:studio
```

Features:
- View all records in each table
- Create, edit, or delete records
- Test relationships visually
- Verify seed data was applied correctly
- No SQL knowledge needed

### Resetting Your Database

To start fresh (clear all data and reapply migrations):

```bash
npx prisma migrate reset
```

**âš ï¸ WARNING:** This command:
- Drops the entire database
- Recreates it from scratch
- Reapplies all migrations in order
- Runs seed script again
- **All data is permanently deleted**

**Use Cases:**
- Development: When you've corrupted data
- Testing: To get a clean slate
- CI/CD: To test migration chain end-to-end

### Idempotency in Seeding

Our seed script uses `upsert` (Update or Insert) to ensure idempotency:

```typescript
const user = await prisma.user.upsert({
  where: { email: 'alice@campusnotes.com' },
  update: {},              // No changes if exists
  create: {                // Only create if doesn't exist
    email: 'alice@campusnotes.com',
    name: 'Alice Johnson',
    // ...
  },
});
```

**Benefits:**
- âœ… Run seed multiple times safely - no duplicates
- âœ… Update existing data if needed
- âœ… Safe for production scenarios

### Production Migration Strategy

**Before running migrations in production, follow these steps:**

1. **Backup Your Database**
   ```bash
   # PostgreSQL backup example
   pg_dump mydb > backup_$(date +%Y%m%d_%H%M%S).sql
   ```

2. **Test Migrations in Staging**
   - Run migrations in staging environment first
   - Verify data integrity
   - Test rollback procedures

3. **Schedule a Maintenance Window**
   - Inform users about downtime
   - Clear active connections
   - Perform backup
   - Apply migration
   - Run verification tests

4. **Monitor After Migration**
   - Check application logs
   - Verify data consistency
   - Monitor database performance
   - Have rollback plan ready

5. **Keep Rollback Ready**
   - If something goes wrong, restore from backup
   - Review error logs
   - Document the issue
   - Plan fix and retest

### Rollback Strategy

**For PostgreSQL, backup restoration:**

```bash
# Restore from backup
psql mydb < backup_20260122.sql

# Or use Prisma to reset and re-seed
npx prisma migrate resolve --rolled-back [migration_name]
```

### Safe Migration Practices

âœ… **DO:**
- Name migrations descriptively: `add_role_to_user`, not `update_schema`
- Test migrations locally before applying to production
- Keep migrations small and focused
- Document complex migrations in commit messages
- Always backup production before migrations
- Run migrations during low-traffic periods

âŒ **DON'T:**
- Make multiple unrelated changes in one migration
- Manually edit generated migration SQL (except for comments)
- Skip testing migrations
- Apply migrations directly to production without staging
- Delete migration files (even if unused)
- Mix schema changes with data transformations

### Common Migration Scenarios

#### Adding a New Model
```bash
# Update schema.prisma with new model
npx prisma migrate dev --name add_comment_model
```

#### Adding a Field with Default Value
```prisma
model Note {
  // ... existing fields ...
  status String @default("draft")  // New field
}
```

#### Creating Indices for Performance
```prisma
model Note {
  // ... fields ...
  @@index([userId])    // Speed up queries
  @@index([courseId])
}
```

#### Making a Field Required (Careful!)
```prisma
model User {
  // Before: email String?
  // After:  email String   // Add migration to set default values first
}
```

### Verification Checklist

After running migrations and seed:

- [ ] Migration files created in `prisma/migrations/`
- [ ] Database tables exist with correct schema
- [ ] All relationships properly created
- [ ] Seed data appears in database
- [ ] Prisma Client generated successfully
- [ ] Can query data with type safety
- [ ] Prisma Studio displays all records
- [ ] No data loss or corruption

### Database Commands Reference

```bash
# Development workflow
npm run db:migrate     # Create and apply migration
npm run db:seed        # Run seed script
npm run db:studio      # Open Prisma Studio GUI
npm run db:reset       # Reset database to clean state

# Advanced
npx prisma migrate dev --name feature_name      # Create named migration
npx prisma migrate deploy                        # Apply migrations (production)
npx prisma migrate resolve --rolled-back name   # Mark migration as rolled back
npx prisma migration resolve --applied name     # Mark migration as applied
npx prisma db push                              # Prototype: push schema to DB
npx prisma db pull                              # Introspect: pull schema from DB
```

### Creative Reflection: Production Migration Safety

**Q: If your app were live in production, what steps would you take before running a migration to make sure no data is lost or corrupted?**

**A:** Production migrations are critical operations that require careful planning:

**Pre-Migration Checklist:**

1. **Backup Everything**
   - Create full database backup
   - Export backup to off-site storage
   - Test backup restoration procedure
   - Document backup location and access

2. **Test in Staging**
   - Clone production database to staging
   - Apply migration to staging environment
   - Run full test suite
   - Verify data integrity
   - Check performance impact
   - Simulate rollback if needed

3. **Plan Maintenance Window**
   - Schedule during low-traffic period
   - Notify users 24-48 hours in advance
   - Have rollback team ready
   - Prepare communication template

4. **Preparation**
   - Brief migration team on plan
   - Review migration SQL manually
   - Prepare rollback scripts
   - Set up monitoring dashboards
   - Verify database connectivity

5. **During Migration**
   - Stop application (prevent new queries)
   - Clear connection pool
   - Run migration (with timeout limits)
   - Verify schema changes applied
   - Run data validation checks
   - Re-enable application gradually

6. **Post-Migration**
   - Monitor error logs for 2 hours
   - Check database performance metrics
   - Verify all application features work
   - Document actual migration time
   - Collect metrics for future migrations

**Why This Matters:**
- Data loss = business impact
- Downtime costs money
- User trust is fragile
- Regulatory compliance (GDPR, HIPAA, etc.)
- Financial/legal implications

**Key Insight:** With great schema changes come great responsibility. The 30 minutes spent planning prevents days of disaster recovery.

---

